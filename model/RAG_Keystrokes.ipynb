{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vvQfycnZEiFk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential #type: ignore\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Attention #type: ignore\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau #type: ignore\n",
        "from tensorflow.keras.regularizers import l2 #type: ignore\n",
        "from scipy.stats import entropy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_keystroke_data(num_samples, is_human=True):\n",
        "    data = []\n",
        "    for _ in range(num_samples):\n",
        "        sequence = []\n",
        "        sequence_length = np.random.randint(20, 100)\n",
        "\n",
        "        keystroke_times = []\n",
        "        pause_times = []\n",
        "        key_hold_times = []\n",
        "\n",
        "        key_distances = []\n",
        "\n",
        "        errors_made = 0\n",
        "        corrections_made = 0\n",
        "\n",
        "        copy_paste_events = 0\n",
        "\n",
        "        for i in range(sequence_length):\n",
        "            if is_human:\n",
        "                keystroke_time = np.random.normal(0.2, 0.05)\n",
        "                pause_time = np.random.normal(0.5, 0.2)\n",
        "                key_hold_time = np.random.normal(0.1, 0.03)\n",
        "                key_distance = np.random.normal(2, 1)\n",
        "            else:\n",
        "                keystroke_time = np.random.normal(0.05, 0.01)\n",
        "                pause_time = np.random.normal(0.1, 0.05)\n",
        "                key_hold_time = np.random.normal(0.05, 0.01)\n",
        "                key_distance = np.random.normal(1.5, 0.5)\n",
        "\n",
        "            keystroke_times.append(keystroke_time)\n",
        "            pause_times.append(pause_time)\n",
        "            key_hold_times.append(key_hold_time)\n",
        "            key_distances.append(key_distance)\n",
        "\n",
        "            if is_human and np.random.random() < 0.05:\n",
        "                errors_made += 1\n",
        "                if np.random.random() < 0.8:\n",
        "                    corrections_made += 1\n",
        "\n",
        "            if (not is_human and np.random.random() < 0.1) or (is_human and np.random.random() < 0.02):\n",
        "                copy_paste_events += 1\n",
        "\n",
        "        avg_keystroke_time = np.mean(keystroke_times)\n",
        "        std_keystroke_time = np.std(keystroke_times)\n",
        "        avg_pause_time = np.mean(pause_times)\n",
        "        std_pause_time = np.std(pause_times)\n",
        "        avg_key_hold_time = np.mean(key_hold_times)\n",
        "        std_key_hold_time = np.std(key_hold_times)\n",
        "\n",
        "        typing_speed = len(keystroke_times) / sum(pause_times)\n",
        "\n",
        "        rhythm_consistency = entropy(keystroke_times)\n",
        "\n",
        "        avg_key_distance = np.mean(key_distances)\n",
        "        std_key_distance = np.std(key_distances)\n",
        "\n",
        "        error_rate = errors_made / sequence_length\n",
        "        correction_rate = corrections_made / max(errors_made, 1)\n",
        "\n",
        "        copy_paste_frequency = copy_paste_events / sequence_length\n",
        "\n",
        "        if is_human:\n",
        "            mouse_speed = np.random.normal(500, 100)\n",
        "            mouse_acceleration = np.random.normal(200, 50)\n",
        "            mouse_jerk = np.random.normal(100, 30)\n",
        "        else:\n",
        "            mouse_speed = np.random.normal(800, 50)\n",
        "            mouse_acceleration = np.random.normal(100, 20)\n",
        "            mouse_jerk = np.random.normal(50, 10)\n",
        "\n",
        "        features = [\n",
        "            avg_keystroke_time, std_keystroke_time,\n",
        "            avg_pause_time, std_pause_time,\n",
        "            avg_key_hold_time, std_key_hold_time,\n",
        "            typing_speed, rhythm_consistency,\n",
        "            avg_key_distance, std_key_distance,\n",
        "            error_rate, correction_rate,\n",
        "            copy_paste_frequency,\n",
        "            mouse_speed, mouse_acceleration, mouse_jerk\n",
        "        ]\n",
        "\n",
        "        data.append(features)\n",
        "\n",
        "    return data\n",
        "\n",
        "num_human_samples = 15000\n",
        "num_bot_samples = 15000\n",
        "\n",
        "human_data = generate_keystroke_data(num_human_samples, is_human=True)\n",
        "bot_data = generate_keystroke_data(num_bot_samples, is_human=False)"
      ],
      "metadata": {
        "id": "dz7EyIz9EzkE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_human_samples = 15000\n",
        "num_bot_samples = 15000\n",
        "\n",
        "human_data = generate_keystroke_data(num_human_samples, is_human=True)\n",
        "bot_data = generate_keystroke_data(num_bot_samples, is_human=False)"
      ],
      "metadata": {
        "id": "HREvcF1lFE2f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\n",
        "    'avg_keystroke_time', 'std_keystroke_time',\n",
        "    'avg_pause_time', 'std_pause_time',\n",
        "    'avg_key_hold_time', 'std_key_hold_time',\n",
        "    'typing_speed', 'rhythm_consistency',\n",
        "    'avg_key_distance', 'std_key_distance',\n",
        "    'error_rate', 'correction_rate',\n",
        "    'copy_paste_frequency',\n",
        "    'mouse_speed', 'mouse_acceleration', 'mouse_jerk'\n",
        "]"
      ],
      "metadata": {
        "id": "Sm_Yb2jwFPbl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_human = pd.DataFrame(human_data, columns=columns)\n",
        "df_bot = pd.DataFrame(bot_data, columns=columns)\n",
        "\n",
        "df_human['target'] = 'human'\n",
        "df_bot['target'] = 'bot'\n",
        "\n",
        "df = pd.concat([df_human, df_bot], ignore_index=True)\n",
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "QBo-FtAGFdsf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(df):\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    problematic_columns = df.columns[df.isin([np.inf, -np.inf, np.nan]).any()].tolist()\n",
        "\n",
        "    print(\"Columns with NaN or infinite values:\")\n",
        "    for col in problematic_columns:\n",
        "        nan_count = df[col].isna().sum()\n",
        "        inf_count = np.isinf(df[col]).sum()\n",
        "        print(f\"{col}: NaN count = {nan_count}, Inf count = {inf_count}\")\n",
        "\n",
        "    for col in problematic_columns:\n",
        "        median_value = df[col].median()\n",
        "        df[col] = df[col].replace([np.inf, -np.inf, np.nan], median_value)\n",
        "\n",
        "    for column in df.columns:\n",
        "        if df[column].dtype in ['float64', 'int64']:\n",
        "            lower_bound = df[column].quantile(0.001)\n",
        "            upper_bound = df[column].quantile(0.999)\n",
        "            df[column] = df[column].clip(lower_bound, upper_bound)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "qkfgorbeFqP8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = clean_data(df)\n",
        "df['target'] = (df['target'] == 'bot').astype(int)\n",
        "\n",
        "X = df.drop('target', axis=1).values\n",
        "y = df['target'].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thFoqS0PFvMl",
        "outputId": "441f793d-7031-4aec-c8e6-2850b684cdd5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with NaN or infinite values:\n",
            "rhythm_consistency: NaN count = 27, Inf count = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "7Axu-o-JFx7u"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))"
      ],
      "metadata": {
        "id": "hBUv-AA5F4BB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rag_model(input_shape):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    # First LSTM layer\n",
        "    lstm_out = LSTM(128, return_sequences=True, kernel_regularizer=l2(0.01))(inputs)\n",
        "    lstm_out = BatchNormalization()(lstm_out)\n",
        "    lstm_out = Dropout(0.3)(lstm_out)\n",
        "\n",
        "    attention_out = Attention()([lstm_out, lstm_out])\n",
        "\n",
        "    lstm_out = LSTM(64, kernel_regularizer=l2(0.01))(attention_out)\n",
        "    lstm_out = BatchNormalization()(lstm_out)\n",
        "    lstm_out = Dropout(0.3)(lstm_out)\n",
        "\n",
        "    dense_out = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(lstm_out)\n",
        "    dense_out = BatchNormalization()(dense_out)\n",
        "    dense_out = Dropout(0.3)(dense_out)\n",
        "\n",
        "    outputs = Dense(1, activation='sigmoid')(dense_out)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "jJxgsENsF8x_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_rag_model((1, X_train_reshaped.shape[2]))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "GQtgbgx4GAQZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)"
      ],
      "metadata": {
        "id": "qpl4z3UjGjDc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_reshaped, y_train,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=50,\n",
        "                    batch_size=64,\n",
        "                    callbacks=[early_stopping, reduce_lr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7Xi8MysGm3H",
        "outputId": "5809b8d0-7549-42d5-977b-603af1dda6a5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (64, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9746 - loss: 1.3920 - val_accuracy: 1.0000 - val_loss: 0.5567 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0790 - val_accuracy: 1.0000 - val_loss: 0.1918 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 0.0029 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 8.5810e-04 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.6367e-04 - val_accuracy: 1.0000 - val_loss: 5.9875e-04 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 7.0959e-04 - val_accuracy: 1.0000 - val_loss: 4.8407e-04 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.0496e-04 - val_accuracy: 1.0000 - val_loss: 4.2445e-04 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.3377e-04 - val_accuracy: 1.0000 - val_loss: 4.0897e-04 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.9857e-04 - val_accuracy: 1.0000 - val_loss: 3.7206e-04 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.4727e-04 - val_accuracy: 1.0000 - val_loss: 3.4627e-04 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 4.4180e-04 - val_accuracy: 1.0000 - val_loss: 3.2968e-04 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.8553e-04 - val_accuracy: 1.0000 - val_loss: 3.3290e-04 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.8543e-04 - val_accuracy: 1.0000 - val_loss: 3.1011e-04 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.3317e-04 - val_accuracy: 1.0000 - val_loss: 2.7868e-04 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 3.0572e-04 - val_accuracy: 1.0000 - val_loss: 2.4431e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.9650e-04 - val_accuracy: 1.0000 - val_loss: 2.3004e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.8093e-04 - val_accuracy: 1.0000 - val_loss: 2.3031e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.8330e-04 - val_accuracy: 1.0000 - val_loss: 2.3268e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.7704e-04 - val_accuracy: 1.0000 - val_loss: 2.2126e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.7148e-04 - val_accuracy: 1.0000 - val_loss: 2.1561e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.6790e-04 - val_accuracy: 1.0000 - val_loss: 2.3291e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.5227e-04 - val_accuracy: 1.0000 - val_loss: 2.1021e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.4676e-04 - val_accuracy: 1.0000 - val_loss: 2.0176e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.3823e-04 - val_accuracy: 1.0000 - val_loss: 2.0000e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.4184e-04 - val_accuracy: 1.0000 - val_loss: 2.0656e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.3519e-04 - val_accuracy: 1.0000 - val_loss: 1.9890e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.3030e-04 - val_accuracy: 1.0000 - val_loss: 2.0926e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.2466e-04 - val_accuracy: 1.0000 - val_loss: 1.9607e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.3162e-04 - val_accuracy: 1.0000 - val_loss: 1.9051e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.2627e-04 - val_accuracy: 1.0000 - val_loss: 1.8095e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.0744e-04 - val_accuracy: 1.0000 - val_loss: 1.7009e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.9531e-04 - val_accuracy: 1.0000 - val_loss: 1.7673e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.8225e-04 - val_accuracy: 1.0000 - val_loss: 1.4799e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8371e-04 - val_accuracy: 1.0000 - val_loss: 1.7940e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.8484e-04 - val_accuracy: 1.0000 - val_loss: 1.4238e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7312e-04 - val_accuracy: 1.0000 - val_loss: 2.0797e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.7638e-04 - val_accuracy: 1.0000 - val_loss: 1.3398e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.5804e-04 - val_accuracy: 1.0000 - val_loss: 1.2574e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.5527e-04 - val_accuracy: 1.0000 - val_loss: 1.1395e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.4362e-04 - val_accuracy: 1.0000 - val_loss: 1.2820e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.3852e-04 - val_accuracy: 1.0000 - val_loss: 1.2954e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3067e-04 - val_accuracy: 1.0000 - val_loss: 1.1059e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.3389e-04 - val_accuracy: 1.0000 - val_loss: 1.0029e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.2499e-04 - val_accuracy: 1.0000 - val_loss: 1.0033e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.1862e-04 - val_accuracy: 1.0000 - val_loss: 1.0623e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1437e-04 - val_accuracy: 1.0000 - val_loss: 8.6985e-05 - learning_rate: 1.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.0397e-04 - val_accuracy: 1.0000 - val_loss: 1.0251e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.0457e-04 - val_accuracy: 1.0000 - val_loss: 9.4091e-05 - learning_rate: 1.0000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.9971e-05 - val_accuracy: 1.0000 - val_loss: 9.4531e-05 - learning_rate: 1.0000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.3712e-05 - val_accuracy: 1.0000 - val_loss: 7.9067e-05 - learning_rate: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRWxoePLG6wD",
        "outputId": "b3bc1e01-6319-46f2-b9e0-8546b395a54c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.8997e-05\n",
            "Test Loss: 7.9021614510566e-05, Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_bot(new_data):\n",
        "    if new_data.ndim == 1:\n",
        "        new_data = new_data.reshape(1, -1)\n",
        "\n",
        "    new_data_scaled = scaler.transform(new_data)\n",
        "\n",
        "    new_data_reshaped = new_data_scaled.reshape((new_data_scaled.shape[0], 1, new_data_scaled.shape[1]))\n",
        "\n",
        "    prediction = model.predict(new_data_reshaped)\n",
        "\n",
        "    is_bot = prediction > 0.5\n",
        "    confidence = prediction if is_bot else 1 - prediction\n",
        "\n",
        "    return is_bot[0][0], confidence[0][0]\n",
        "\n",
        "real_input = np.array([0.2, 0.05, 0.5, 0.1, 0.1, 0.02, 5.0, 0.8, 2.0, 0.5, 0.01, 0.005, 0.001, 300, 100, 50])\n",
        "is_bot, confidence = predict_bot(real_input)\n",
        "print(f\"Is bot: {is_bot}, Confidence: {confidence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqE-FuC5HfQM",
        "outputId": "7c81c71f-eebe-4c5f-fb3f-6f7a1d16d2ee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (1, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612ms/step\n",
            "Is bot: False, Confidence: 0.9999710321426392\n"
          ]
        }
      ]
    }
  ]
}